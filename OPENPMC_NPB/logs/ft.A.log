

 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.63
 Mop/s total     =                   267.95
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.63
 Mop/s total     =                   268.01
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.62
 Mop/s total     =                   268.06
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.64
 Mop/s total     =                   267.89
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.66
 Mop/s total     =                   267.67
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.65
 Mop/s total     =                   267.78
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.65
 Mop/s total     =                   267.80
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.66
 Mop/s total     =                   267.70
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.64
 Mop/s total     =                   267.86
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1


 NAS Parallel Benchmarks 2.3 OpenMP C version - FT Benchmark

 Size                : 256x256x128
 Iterations          :           6
T =     1     Checksum =     5.046735008193e+02     5.114047905510e+02
T =     2     Checksum =     5.059412319734e+02     5.098809666433e+02
T =     3     Checksum =     5.069376896287e+02     5.098144042213e+02
T =     4     Checksum =     5.077892868474e+02     5.101336130759e+02
T =     5     Checksum =     5.085233095391e+02     5.104914655194e+02
T =     6     Checksum =     5.091487099959e+02     5.107917842803e+02
Result verification successful
cclass = A


 FT Benchmark Completed
 Class           =                        A
 Size            =              256x256x128
 Iterations      =                        6
 Threads         =                        1
 Time in seconds =                    26.66
 Mop/s total     =                   267.69
 Operation type  =           floating point
 Verification    =               SUCCESSFUL
 Version         =                      2.3
 Compile date    =              21 Feb 2012

 Compile options:
    CC           = gcc
    CLINK        = gcc
    C_LIB        = -lm
    C_INC        = -I../common
    CFLAGS       = -O3 
    CLINKFLAGS   = (none)
    RAND         = randdp
/***********************/ 
/* Input Configuration */ 
/***********************/ 
====> GPU Block Size: 512 
/**********************/ 
/* Used Optimizations */ 
/**********************/ 
====> MallocPitch Opt is used.
====> MatrixTranspose Opt is used.
====> ParallelLoopSwap Opt is used.
====> LoopCollapse Opt is used.
====> Unrolling-on-reduction Opt is used.
====> Allocate GPU variables as global ones.
====> Optimize globally allocated GPU variables .
====> CPU-GPU Mem Transfer Opt Level: 4
====> Cuda Malloc Opt Level: 1
====> Assume that all loops have non-zero iterations.
====> Cache shared scalar variables onto GPU registers.
====> Cache shared array elements onto GPU registers.
====> Cache private array variables onto GPU shared memory.
====> local array reduction variable configuration = 1
